{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Breast_Cancer_Classification_final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "26Dn6xpuHUJD"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxfCfvXNqkb"
      },
      "source": [
        "!nvidia-smi -L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsXCSPFT4do_"
      },
      "source": [
        "!pip install wget\n",
        "!wget \"https://scholar.cu.edu.eg/Dataset_BUSI.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMf_-XgF6Kzr"
      },
      "source": [
        "!unzip -qq \"/content/Dataset_BUSI.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5TyIZyZKGbz"
      },
      "source": [
        "# ==== Install Dependencies\n",
        "!pip install -q efficientnet-pytorch\n",
        "!pip install -q albumentations\n",
        "!pip install -U -q pytorch-fanatics \n",
        "!pip install -q pytorch_ranger"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCkFVHBTKXJ0"
      },
      "source": [
        "# ==== Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "import random\n",
        "import os\n",
        "\n",
        "\n",
        "import albumentations as aug\n",
        "from albumentations.pytorch.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from pytorch_fanatics.dataloader import Cloader\n",
        "from pytorch_fanatics.utils import EarlyStop ,LRFinder \n",
        "from pytorch_fanatics.trainer import Trainer\n",
        "from pytorch_fanatics.logger import Logger\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\") \n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "from pytorch_ranger import Ranger\n",
        "\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "from pathlib import Path\n",
        "\n",
        "from torchvision import transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T-IrGQh62jl"
      },
      "source": [
        "import os\n",
        "\n",
        "asps = []\n",
        "for root, dirs, files in os.walk('/content/Dataset_BUSI_with_GT/benign/'):\n",
        "    # print(root)\n",
        "    # print(dirs)\n",
        "    # print(files)\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):\n",
        "            asps.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK505pha9icL"
      },
      "source": [
        "image_id=[]\n",
        "labels=[]\n",
        "for x in range(len(asps)):\n",
        "  asps[x]=os.path.join('/content/Dataset_BUSI_with_GT/benign',asps[x])\n",
        "  image_id.append(asps[x])\n",
        "  labels.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6G3g8FPl-95z"
      },
      "source": [
        "import os\n",
        "\n",
        "asps = []\n",
        "for root, dirs, files in os.walk('/content/Dataset_BUSI_with_GT/malignant/'):\n",
        "    # print(root)\n",
        "    # print(dirs)\n",
        "    # print(files)\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):\n",
        "            asps.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RbSGTD5e_Vti"
      },
      "source": [
        "# image_id=[]\n",
        "for x in range(len(asps)):\n",
        "  asps[x]=os.path.join('/content/Dataset_BUSI_with_GT/malignant/',asps[x])\n",
        "  image_id.append(asps[x])\n",
        "  labels.append(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZr_8jDYAAEE"
      },
      "source": [
        "import os\n",
        "asps = []\n",
        "for root, dirs, files in os.walk('/content/Dataset_BUSI_with_GT/normal/'):\n",
        "    # print(root)\n",
        "    # print(dirs)\n",
        "    # print(files)\n",
        "    for file in files:\n",
        "        if file.endswith('.png'):\n",
        "            asps.append(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5f4vZVANAWdS"
      },
      "source": [
        "# image_id=[]\n",
        "for x in range(len(asps)):\n",
        "  asps[x]=os.path.join('/content/Dataset_BUSI_with_GT/normal/',asps[x])\n",
        "  image_id.append(asps[x])\n",
        "  labels.append(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF0ciXLGAxrw"
      },
      "source": [
        "d={'image_id':image_id,'labels':labels}\n",
        "df=pd.DataFrame(d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xo61ovOWB-NF"
      },
      "source": [
        "df=df.sample(frac=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTIvuHfDCSj5"
      },
      "source": [
        "df=df.reset_index(drop=True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyuWoK-eNwYS"
      },
      "source": [
        "map={'Benign':0,'Malignant':1,'Normal':2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iny4DZoKnYxP"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QhQHolYShOM"
      },
      "source": [
        "from sklearn.model_selection import train_test_split as tts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sX3Cb4RZDIyo"
      },
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "seed_everything(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2tX1Of8HUIf"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUsLanVCtenT"
      },
      "source": [
        "!mkdir \"/content/drive/MyDrive/HackNagpur/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xpje_XSoNzse"
      },
      "source": [
        "save_root = \"/content/drive/MyDrive/HackNagpur/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOIEEnXKOXDe"
      },
      "source": [
        "# training_data_path = \"/content/ISIC_2019_Training_Input/ISIC_2019_Training_Input\"\n",
        "\n",
        "X_train , X_val ,Y_train , Y_val = tts(df, df.labels.values, test_size=0.25\n",
        "                                       ,random_state=42,stratify=df.labels.values)\n",
        "X_train       = X_train.reset_index(drop=True)\n",
        "X_val         = X_val.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q2Ua3O5fOW-I"
      },
      "source": [
        "# ===== Augmentations\n",
        "\n",
        "mean       = (0.485, 0.456, 0.406)\n",
        "std        = (0.229, 0.224, 0.225)\n",
        "image_size=224\n",
        "train_tfms = aug.Compose([\n",
        "            aug.Resize(224,224),\n",
        "            aug.RandomSizedCrop(min_max_height=(64,224),height=224,width=224,p=0.5),\n",
        "            aug.HorizontalFlip(p=0.5),\n",
        "            aug.RandomBrightnessContrast(0.1,0.1),\n",
        "            #aug.HueSaturationValue(10,10,10),\n",
        "            aug.RGBShift(),\n",
        "            aug.RandomContrast(limit=0.2),\n",
        "            aug.RandomGamma(),\n",
        "            #aug.ShiftScaleRotate(rotate_limit=(-45,45)),\n",
        "            aug.GaussNoise(p=0.35),\n",
        "            aug.IAASharpen(),\n",
        "            aug.ToGray(p=0.35),\n",
        "            aug.CLAHE(clip_limit=4.0, p=0.7),\n",
        "            #aug.RandomSizedCrop(min_max_height=(64,256),height=256,width=256,p=0.5),\n",
        "            aug.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
        "            aug.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
        "            #aug.Cutout(max_h_size=int(image_size * 0.375), max_w_size=int(image_size * 0.375), num_holes=1, p=0.7),\n",
        "            aug.Normalize(mean,std,max_pixel_value=255.0,always_apply=True),\n",
        "            ])\n",
        "\n",
        "test_tfms  = aug.Compose([\n",
        "            aug.Resize(224,224),\n",
        "            aug.Normalize(mean,std,max_pixel_value=255.0,always_apply=True),\n",
        "            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tOUhwfaO5fR"
      },
      "source": [
        "# training_data_path='/content/train'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkAucLGgI9aa"
      },
      "source": [
        "import numpy as np\n",
        "from PIL import Image\n",
        "from PIL import ImageFile   #ImageFile contains support for PIL to open and save images\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES=True  #If image is truncated(or corrupt) then also load it..\n",
        "import torch\n",
        "\n",
        "class Cloader:\n",
        "    def __init__(self,image_path,targets,resize=None,transforms=None):\n",
        "        self.image_path=image_path\n",
        "        self.targets=targets\n",
        "        self.resize=resize\n",
        "        self.transforms=transforms\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        image = Image.open(self.image_path[idx]).convert(\"RGB\")\n",
        "        targets = self.targets[idx]\n",
        "        if self.resize is not None:\n",
        "            image = image.resize(\n",
        "                (self.resize[1], self.resize[0]), resample=Image.BILINEAR\n",
        "            )\n",
        "        image = np.array(image)\n",
        "        if self.transforms is not None:\n",
        "            augmented = self.transforms(image=image)\n",
        "            image = augmented[\"image\"]\n",
        "        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n",
        "        return {\n",
        "            \"image\": torch.tensor(image, dtype=torch.float),\n",
        "            \"targets\": torch.tensor(targets, dtype=torch.long),\n",
        "        }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvu4IaecOW6a"
      },
      "source": [
        "train_images     = X_train.image_id.values.tolist()\n",
        "# train_images     = [os.path.join(training_data_path, i+\".png\") for i in train_images]\n",
        "\n",
        "test_images      = X_val.image_id.values.tolist()\n",
        "# test_images      = [os.path.join(training_data_path, i+\".png\") for i in test_images]\n",
        "\n",
        "train_dataset    = Cloader(train_images,X_train.labels.values,(224,224),train_tfms)\n",
        "#train_dataset    = CutMix(train_dataset, num_class=8, beta=1.0, prob=0.5, num_mix=2)\n",
        "test_dataset     = Cloader(test_images,X_val.labels.values,(224,224),test_tfms)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset,batch_size=32,shuffle=True,num_workers=0)\n",
        "val_dataloader   = DataLoader(test_dataset,batch_size=32,shuffle=False,num_workers=0)\n",
        "\n",
        "device           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EkzwBWrPCmN"
      },
      "source": [
        "# ===== Define model\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.base_model=EfficientNet.from_pretrained('efficientnet-b0',num_classes=3)\n",
        "    def forward(self, image, targets):\n",
        "        batch_size, _, _, _ = image.shape\n",
        "        out = self.base_model(image)\n",
        "        targets = torch.tensor(targets,dtype=torch.int64)\n",
        "        loss = nn.CrossEntropyLoss()(out.view(batch_size,3), targets)\n",
        "        return out, loss\n",
        "\n",
        "model = Net()\n",
        "model.to(device);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc_weQvHPCj0"
      },
      "source": [
        "def softmax(array):\n",
        "    return np.exp(array)/np.sum(np.exp(array),axis=1).reshape(-1,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcSuSfGXPChd"
      },
      "source": [
        "optimizer = Ranger(model.parameters(),lr=1e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer,factor=0.8, mode=\"min\", patience=2)\n",
        "\n",
        "trainer   = Trainer(model=model,optimizer=optimizer,device=device,val_scheduler=scheduler)\n",
        "logger    = Logger()\n",
        "\n",
        "es        = EarlyStop(patience=5,mode=\"min\") # mode = min to minimise loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWmkwlMMPCRE"
      },
      "source": [
        "epochs = 30\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    logger.write(f\"+ ===== Epoch {epoch+1}/{epochs} ===== +\")\n",
        "    train_loss              = trainer.train(train_dataloader)\n",
        "    y_true,y_pred ,val_loss = trainer.evaluate(val_dataloader)\n",
        "    y_pred                  = softmax(y_pred)\n",
        "    accuracy                = accuracy_score(y_true,np.argmax(y_pred,axis=1))\n",
        "    es(val_loss,model,model_path =\"/content/drive/MyDrive/HackNagpur/best.pth\")\n",
        "    logger.write(f\"train_loss {train_loss} val_loss {val_loss} \")\n",
        "    logger.write(f\"val accuracy_score {accuracy} \")\n",
        "    logger.write(\" \")\n",
        "    if es.early_stop:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}